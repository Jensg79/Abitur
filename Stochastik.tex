\section{Wiederholung der Wahrscheinlichkeitsbegriffe}
\begin{merke}{Grundbegriffe der Wahrscheinlichkeit}{}
    Ein Ereignis A ist eine Teilmenge der Ergebnisraumes $\Omega$.\\
    Ein Ereignis A tritt ein, wenn das Versuchsergebnis $\omega$ in A enthalten ist, also wenn gilt: $\omega \in A$.\\
    Alle Elemente von $\Omega$, die nicht zum Ereignis A gehören, fasst man unter dem Namen Gegenereignis $\Bar{A}$ von $A$ zusammen. Damit ist $\Bar{A} = \Omega \setminus A$.
\end{merke}
\begin{b8d}{Mengenalgebra}{}
    \begin{itemize}
        \item Schnittmenge $A\cap B$: Menge der gemeinsamen Ergebnisse von A und B
        \item Vereinigungsmenge $A\cup B$: Menge der Ergebnisse die sowohl in A als auch in B liegen.
    \end{itemize}
\end{b8d}
\begin{merke}{Unvereinbar}{}
Zwei Ereignisse A und B heißen unvereinbar, wenn $A\cap B = \{ \}$.
\end{merke}
\section{Axiomatischer Aufbau der Wahrscheinlichkeit}
Der axiomatische Aufbau der Wahrscheinlichkeitsrechnung geht auf den russischen Mathematiker Kolmogoroff zurück. Hierbei wird versucht, die gesamte Stochastik mit möglichst wenigen Annahmen zu beschreiben. Die sogenannten Axiome sind hierbei Grundannahmen die weder bewiesen noch widerlegt werden können. Hierbei wird die Berechnung der Wahrscheinlichkeit durch eine Funktion $P$ beschrieben.\\
\begin{defi}{}{Grundaxiome der Stochastik}
    Eine Funktion $P$, die jedem Ereignis A eine Wahrscheinlichkeit $P(A)$ zuordnet nennt man Wahrscheinlichkeitsverteilung genau dann wenn sie folgende Eigenschaften erfüllt.
\end{defi}
\section{Bedingte Wahrscheinlichkeit}\index{Wahrscheinlichkeit!bedingte Wahrscheinlichkeit}
Wahrscheinlichkeiten von Ereignissen können sich verändern, wenn bereits andere Ereignisse eingetreten sind. Um diesen Einfluss zu untersuchen, wird der Begriff der bedingten Wahrscheinlichkeit eingeführt.
\begin{defi}{Die bedingte Wahrscheinlichkeit}{}
\index{Bedingte Wahrscheinlichkeit}
   Die Wahrscheinlichkeit eines Ereignisses B unter der Bedingung, dass das Ereignis A bereits eingetreten ist lässt sich durch folgende Zusammenhang berechnen: $$P_A(B) = \dfrac{P(A\cap B)}{P(A)}$$   
\end{defi}
Durch die Betrachtung eines zweistufigen Baumdiagramms ist es möglich, die Definition für die bedingte Wahrsheinlichkeit zu zeigen.
\begin{merke*}{Die Herleitung der bedingten Wahrscheinlichkeit}{}
\begin{multicols}{2}
\scalebox{0.65}{
% allgemeines Layout des Baums
\tikzstyle{level 1}=[level distance=2.5cm, sibling distance=5cm]
\tikzstyle{level 2}=[level distance=2.5cm, sibling distance=4cm]
% definiert Knoten- und Endpunkte
% text width ändert die Boxbreite wobei 1em einem Zeichen entspricht
\tikzstyle{bag} = [circle, draw, text width=1em, inner sep=2pt, text centered]
\tikzstyle{end} = [circle, minimum width=4pt, fill, inner sep=0pt]
\begin{tikzpicture}[grow=down]
  \node[bag]{}
  child
  {
    node[bag] {$A$} % beschriftet Knoten 2 in erster Ebene mit X
    child
    {
      node (B) [bag] {$B$} % beschriftet Knoten 4 in zweiter Ebene mit D
      node [below of = B] {$P(A \cap B)$}
      edge from parent
      node[left]  {$P_{A}(B)$} % beschriftet Verbindung zu Knoten 4 (Ebene 2) mit p
} child {
      node[bag] {$\Bar{B}$} % beschriftet Knoten 3 in zweiter Ebene mit C
      edge from parent
      node[right]  {$P_{A}(\Bar{B})$} % beschriftet Verbindung zu Knoten 3 (Ebene 2) mit m
    }
    edge from parent
    node[left]  {$P(A)$} % beschriftet Verbindung zu Knoten 2 (Ebene 1) mit f
} child {
    node[bag] {$\Bar{A}$} % beschriftet Knoten 1 in erster Ebene mit A
    child
    {
      node[bag] {$B$} % beschriftet Knoten 2 in zweiter Ebene mit B
      edge from parent
      node[left]  {$P_{\Bar{A}}(B)$} % beschriftet Verbindung zu Knoten 2 (Ebene 2) mit k
} child {
      node[bag] {$\Bar{B}$} % beschriftet Knoten 1 in zweiter Ebene mit A
      edge from parent
      node[right]  {$P_{\Bar{A}}(B)$} % beschriftet Verbindung zu Knoten 1 (Ebene 2) mit i
    }
    edge from parent
    node[right]  {$P(A)$} % beschriftet Verbindung zu Knoten 1 (Ebene 1) mit w
  };
\end{tikzpicture}}

Nach der ersten Pfadregel berechnet sich die Wahrscheinlichkeit $P(A\cap B)$ durch das Produkt der einzelnen Pfadwahrscheinlichkeiten. Es gilt damit also $$P(A\cap B) = P(A) \cdot P_{A}(B)$$ und daraus folgt die Beziehung: $$P_{A}(B) = \dfrac{P(A \cap B)}{P(A)}$$
\end{multicols}
\end{merke*}
\begin{bsp}{Beispiel für eine bedingte Wahrscheinlichkeit}{}
Für einen Laplace-Würfel sind folgende Ereignisse gegeben:\\
\begin{enumerate}
    \item Ereignis A: Die geworfenen Augenzahl ist durch drei teilbar.
    \item Ereignis B: Die geworfene Augenzahl liegt zwischen 1 und 4.
\end{enumerate}
Nun soll die Wahrscheinlichkeit von A unter der Bedingung B bestimmt werden.\\
\emph{Es wird also die Wahrscheinlichkeit dafür gesucht, dass die gewürfelte Zahl durch drei teilbar ist unter der Bedingung, dass sie zwischen 1 und 4 liegt.}\\[0.5cm]
Für die Wahrscheinlichkeiten gilt damit folgendes: $$P(A) = \dfrac{2}{6} \hspace{0.2cm} \text{und} \hspace{0.2cm} P(B) = \dfrac{4}{6} $$
\scalebox{0.8}{
% allgemeines Layout des Baums
\tikzstyle{level 1}=[level distance=2.5cm, sibling distance=5cm]
\tikzstyle{level 2}=[level distance=2.5cm, sibling distance=4cm]
% definiert Knoten- und Endpunkte
% text width ändert die Boxbreite wobei 1em einem Zeichen entspricht
\tikzstyle{bag} = [circle, draw, text width=1em, inner sep=2pt, text centered]
\tikzstyle{end} = [circle, minimum width=4pt, fill, inner sep=0pt]
\begin{tikzpicture}[grow=down]
  \node[bag]{}
  child
  {
    node[bag] {$B$} % beschriftet Knoten 2 in erster Ebene mit X
    child
    {
      node (B) [bag] {$A$} % beschriftet Knoten 4 in zweiter Ebene mit D
      node [below of = B] {$P(B \cap A) = \dfrac{1}{6}$}
      edge from parent
      node[left]  {$P_{B}(A)$} % beschriftet Verbindung zu Knoten 4 (Ebene 2) mit p
} child {
      node[bag] {$\Bar{A}$} % beschriftet Knoten 3 in zweiter Ebene mit C
      edge from parent
      node[right]  {$P_{B}(\Bar{A})$} % beschriftet Verbindung zu Knoten 3 (Ebene 2) mit m
    }
    edge from parent
    node[left]  {$P(B)$} % beschriftet Verbindung zu Knoten 2 (Ebene 1) mit f
} child {
    node[bag] {$\Bar{B}$} % beschriftet Knoten 1 in erster Ebene mit A
    child
    {
      node[bag] {$A$} % beschriftet Knoten 2 in zweiter Ebene mit B
      edge from parent
      node[left]  {$P_{\Bar{B}}(A)$} % beschriftet Verbindung zu Knoten 2 (Ebene 2) mit k
} child {
      node[bag] {$\Bar{A}$} % beschriftet Knoten 1 in zweiter Ebene mit A
      edge from parent
      node[right]  {$P_{\Bar{B}}(A)$} % beschriftet Verbindung zu Knoten 1 (Ebene 2) mit i
    }
    edge from parent
    node[right]  {$P(\Bar{B})$} % beschriftet Verbindung zu Knoten 1 (Ebene 1) mit w
  };
\end{tikzpicture}}\\
Die Wahrscheinlichkeit für das Ereignis $A\cap B$ entspricht demjenigen Ereignis, dass sowohl B als auch A eintritt. Das entspricht der Menge die nur aus der Augenzahl 3 besteht und damit der Wahrscheinlichkeit $P(A\cap B) = \dfrac{1}{6}$. Aus dem Baumdiagramm folgt damit: $$P(A\cap B) = P(B) \cdot P_{B}(A)$$ und dadurch $$P_{B}(A) = \dfrac{P(A\cap B)}{P(B)} = \dfrac{\dfrac{1}{6}}{\dfrac{4}{6}}= \dfrac{1}{6} \cdot \dfrac{6}{4} = \dfrac{1}{4} $$.
\end{bsp}
\section{Zufallsgrößen und deren Wahrscheinlichkeiten}
\begin{defi}{Zufallsgrößen und Wahrscheinlichkeitsverteilung}{}\index{Zufallsgröße!Definition}
Eine Funktion $X$, die jedem Ergebnis $\omega$ eines Ergebnisraumes $\Omega$ eine reelle Zahl $x$ zuordnet, heißt \textcolor{red}{Zufallsgröße\footnote{Zufallsgröße $\longrightarrow$ ZG}} X.\\
Jeder Wert $x$ einer ZG $X$ tritt mit einer bestimmten Wahrscheinlichkeit $P(X=x)$ auf. Die Funktion, die jedem Wert $x$ einer ZG $X$ die Wahrscheinlichkeit $P(X=x)$ zuordnet, heißt \textcolor{red}{Wahrscheinlichkeitsverteilung} der ZG $X$.\\

Als Beispiel ist hier $P(X=4) = 0,2$ dargestellt.\\
\begin{center}

\begin{tikzpicture}[>=Stealth, scale=0.8]

% Ergebnisraum Omega (kompakter)
\draw[orange] (0,4.5) ellipse (3.2cm and 0.8cm);
\node[orange] at (3.6,5.3) {Ergebnisraum $\Omega$};
\foreach \i/\x/\y in {
  \omega_1/-2.5/4.7,
  \omega_2/-1.5/4.3,
  \omega_3/-0.5/4.8,
  \omega_4/ 0.5/4.3,
  \omega_5/ 1.5/4.7,
  \omega_6/ 2.5/4.3
}{
  \node at (\x,\y) {\(\i\)};
}

% Wertemenge W
% Blauer Hintergrund unter Achse von 1.5 bis 12
\fill[blue!20] (-1.5,2.9) rectangle (4.5,3.1);
\draw[->] (-2.2,3) -- (5,3) node[right] {$x$};
\foreach \x in {-2,-1,0,1,2,3,4}
  \draw (\x,2.9) -- (\x,3.1) node[below=2pt] {\small \x};
\node[blue] at (4.8,3.4) {Wertemenge $W$};

% Grüner Pfeil: Zufallsgröße X
\draw[->, thick, green!60!black] (0.5,4.2) to[bend left=30] (4,3.1);
\node[green!50!black] at (1.5,3.4) {Zufallsgröße $X$};

% P(X = x)-Achse
\draw[->] (-0.1,1.5) -- (3.6,1.5) node[anchor=west] {$P(X = x)$};

% Tick-Marken und Beschriftungen
\foreach \i/\label in {0/0, 1/0.2,  3/0.6, 5/1} {
  \draw (\i*0.6 + 0.3,1.5) -- ++(0,-0.1); % Markierung
  \node at (\i*0.6 + 0.3,1.2) {\label};   % Beschriftung
}

% Roter Pfeil: zweifach gebogen und zeigt exakt auf 0.2 (bei x=0.9, y=1.5)
\draw[->, thick, red]
  (4,2.9) .. controls (5.2,2.3) and (1.4,1.9) .. (0.9,1.5);

\node[red] at (3.4,2.3) {Wahrscheinlichkeitsverteilung};
\end{tikzpicture}  
    
\end{center}
\end{defi}
\begin{merke}{Kumulative Verteilung}{}\index{Zufallsgröße!Kumulative Verteilung}
Die Funktion F, die bei gegebener Zufallsgröße \(X\) jeder reellen Zahl \(x\) die Wahrscheinlichkeit \(P(X\leq x)\) zuordnet, heißt kumulative Verteilungsfunktion der Zufallsgröße \(X\). Hierfür schreibt man \(F:x \mapsto P(X\leq x)\) mit \(x \in \mathds{R}\) und \(P(X\leq x) \in [0;1]\)
\end{merke}
\begin{b8d}{Eigenschaften der kumulativen Verteilung}{}\index{Zufallsgröße!Kumulative Verteilung!Eigenschaften}
Für eine kumulative Verteilungsfunktion \(F\) gilt:
\begin{itemize}
    \item \(\lim\limits_{x\longrightarrow -\infty} F(x) = 0\) und \(\lim\limits_{x\longrightarrow \infty} F(x) = 1\)\textbf{}
    \item Die Funktion \(F\) ist monoton steigend in \(\mathds{R}\)
    \item Der Graph von \(F\) springt bei \(x\), wenn \(P(X\leq x) \neq 0\) ist. Die Höhe des Sprungs beträgt \(P(X=x)\)
    \item Die Wahrscheinlichkeit \(P(a<X\leq b)\), dass die Zufallsgröße \(X\) einen Wert \(x\) aus dem Intervall \(a<X\leq b\) annimmt, kann als Differenz \(F(b) - F(a)\) berechnet werden.
\end{itemize}
\end{b8d}
\section{Erwartungswert und Varianz}
\begin{defi}{Der Erwartungswert}{}\index{Zufallsgröße!Erwartungswert}
Eine ZG nimmt die Werte $x_1, x_2,\ldots , x_n$ mit den Wahrscheinlichkeiten $P(X=x_1), P(X=x_2), \ldots, P(X=x_n)$ an.\\  Dann heißt der zu erwartende Mittelwert \[\mu =E(X) = \sum\limits_{i=1}^n x_i\cdot P(X=x_i)= x_1\cdot P(X=x_1) + x_2\cdot P(X=x_2) +\ldots + x_n \cdot P(X=x_n)\]
    \textcolor{red}{Erwartungswert} von $X$. 
    \end{defi}
    \begin{bem}{Eigenschaften des Erwartungswertes}{}
        \begin{itemize}
            \item Der Erwartungswert $\mu$ ist häufig \textcolor{red}{kein} Wert, den die ZG annimmt.
            \item Ein Spiel heißt \textcolor{red}{\textbf{fair}}, wenn der Erwartungswert des Gewinns eines Glückspiels für jeden Spieler \(0\) ist.
        \end{itemize}
    \end{bem}
    \begin{defi}{Die Varianz}{}\index{Zufallsgröße!Varianz}
  Eine ZG mit $E(X) = \mu$ nehme die Werte $x_1, x_2,\ldots , x_n$ mit den Wahrscheinlichkeiten $P(X=x_1), P(X=x_2), \ldots, P(X=x_n)$ an. \\ 
  Dann heißt die mittlere quadratische Abweichung von $\mu$ \textcolor{red}{Varianz} von $X$: \[Var(X) = \sum\limits_{i=1}^n \left(x_i - \mu\right)^2 \cdot P(X = x_i)= \left(x_1 - \mu\right)^2 \cdot P(X = x_1) + \ldots + \left(x_n - \mu\right)^2 \cdot P(X = x_n)\]
    \end{defi}
    \begin{bem}{Eigenschaften der Varianz}{}\index{Zufallsgröße!Varianz!Eigenschaften}
       Die Werte einer ZG sind häufig Maßzahlen einer Größe. Folglich ist die Varianz von \(X\) die Maßzahl einer Größe, die im Quadrat gemessen wird. Da dies in der Praxis nicht sehr anschaulich ist, wird mit der Standardabweichung ein neues Maß eingeführt.  
    \end{bem}
    \begin{defi}{Die Standardabweichung}{}\index{Zufallsgröße!Standardabweichung}
Die Standardabweichung $\sigma$ einer ZG $X$ bestimmt sich durch $\sigma = \sqrt{Var(X)}$
    \end{defi}
    \section{Kombinatorik}\index{Kombinatorik}
\begin{enumerate}
    \item Permutation als  Anordnung von $n$ Objekten in einer bestimmten Reihenfolge $\longrightarrow n! = n\cdot ( n-1) \cdot (n-2)\cdot \ldots \cdot 3\cdot  2\cdot 1$
    \item Unterscheidungsmöglichkeiten in einem Urnenexperimentes: Man zieht aus einer Menge mit $n$ Elementen $k-$Elemente heraus\\
    \begin{center}
   \begin{tabular}{|c||c|c|}
    \hline
         &  Mit Reihenfolge & Ohne Reihenfolge\\
           \hline\hline
     Mit Zurücklegen   & $n^k$ & $\binom{n+k-1}{k}$\\
     \hline
     Ohne Zurücklegen & $\frac{n!}{\left(n-k\right)!}$& $\binom{n}{k} = \frac{n!}{k!\left(n-k\right)!}$\\
     \hline
    \end{tabular} 
         
    \end{center}
\end{enumerate}
\begin{merke}{Merksatz zum Binomialkoeffizienten}{}\index{Binomialkoeffizient}
Der Binomialkoeffizient \(\binom{n}{k}\) zählt, wie viele Möglichkeiten es gibt, aus \(n\) verschiedenen Elementen genau \(k\) ohne Reihenfolge auszuwählen:
\[\binom{n}{k}=\frac{n!}{k!(n-k)!}\quad (0\le k\le n).\]
\end{merke}
\begin{b8d}{Der Binomialkoeffizient}{}\index{Binomialkoeffizient}
Eigenschaften des Binomialkoeffizienten
\begin{enumerate}
    \item Der Binomialkoeffizient ist symmetrisch $\longrightarrow \binom{n}{k} = \binom{n}{n-k}$
    \item Besondere Werte des Binomialkoeffizienten $\binom{n}{0}= 1; \binom{n}{1} = n$ und $\binom{n}{n}=1$
\end{enumerate}  
\end{b8d}
\section{Hypergeometrische Verteilung}
\begin{bem}{Urnenmodell und „Ziehen mit einem Griff“}{}\index{Urnenmodell}
Viele Zufallssituationen lassen sich als Urnenmodell beschreiben: Es gibt zwei Arten von Objekten (z.,B. „schwarz/weiß“) und man zieht mehrere auf einmal, also \emph{ohne Zurücklegen}. Dann ist nicht die Reihenfolge entscheidend, sondern nur, \emph{wie viele} Objekte einer Art im Ergebnis liegen. Genau hier taucht der Binomialkoeffizient als Zählwerkzeug auf. Das Standardmodell dahinter heißt \emph{hypergeometrische Verteilung}.\index{Hypergeometrische Verteilung}
\end{bem}
\begin{defi}{Hypergeometrische Wahrscheinlichkeit}{}\index{Hypergeometrische Verteilung!Wahrscheinlichkeitsverteilung}
In einer Urne liegen S „Erfolgskugeln“ (z.,B. schwarz) und N-S „Nichterfolgskugeln“ (z.,B. weiß). Es werden n Kugeln ohne Zurücklegen gezogen.
Für \(k\in\{0,1,\dots,n\}\) heißt
\[P(X=k)=\frac{\binom{S}{k}\binom{N-S}{n-k}}{\binom{N}{n}}\]
die \emph{hypergeometrische Wahrscheinlichkeit}, wobei die ZG \(X\) die Anzahl der gezogenen Erfolgskugeln ist.
\end{defi}
\begin{bsp}{Sechs schwarze, vier weiße Kugeln; fünf auf einmal ziehen}{}
In einer Urne liegen 6 schwarze und 4 weiße Kugeln, insgesamt also \(N=10\). Es werden \(n=5\) Kugeln ohne Zurücklegen gezogen. Gesucht ist die Wahrscheinlichkeit dafür, dass \emph{genau drei} schwarze Kugeln darunter sind \((k=3)\).
\end{bsp}
\begin{rechnung}{Berechnung mit Binomialkoeffizienten}{}
Alle 5-Auswahlen aus 10 Kugeln sind gleich wahrscheinlich:\begin{itemize}
    \item \(\binom{10}{5} \longrightarrow\) Anzahl der Möglichkeiten aus 10 Kugeln 5 auszuwählen 
   \item  Anzahl an Möglichkeiten  3 der 6 schwarzen auszuwählen \(\longrightarrow \binom{6}{3}\)
    \item  Anzahl an Möglichkeiten 2 der 4 weißen auszuwählen \(\longrightarrow\binom{4}{2} \) 
\end{itemize}
Damit\\
\(P(X=5)=\frac{\binom{6}{3}\binom{4}{2}}{\binom{10}{5}}
=\frac{20\cdot 6}{252}
=\frac{120}{252}
=\frac{10}{21}\).
\end{rechnung}
\begin{bem}{Einordnung und Verallgemeinerung}{}
Das Vorgehen ist sofort verallgemeinerbar: \(\binom{N}{n}\) zählt alle gleich wahrscheinlichen Auswahlen, und die günstigen Fälle zerfallen in „k aus der einen Gruppe“ mal „n-k aus der anderen Gruppe“. In vielen Anwendungen ist „schwarz“ nur ein Platzhalter für eine Eigenschaft („defekt“, „weiblich“, „Treffer“, \(\dots\)).
\end{bem}
\section{Bernoulli-Experimente und Bernoulli-Kette}
    \begin{defi}{Bernoulli-Experimente und Bernoulli-Kette}{}\index{Bernoulli-Experiment}
    Ein Zufallsexperiment mit genau zwei Ergebnissen heißt \textbf{Bernoulli-Experiment}. Die Wahrscheinlichkeit für einen Treffer wird mit \(p\), die für eine Niete mit \(q\) bezeichnet, wobei \(q=1-p\) gilt.\\
    Ein Zufallsexperiment, das aus \(n\) unabhängigen Durchführungen desselben Bernoulli-Experiments besteht, heißt \textbf{Bernoulli-Kette} der Länge \(n\) mit dem Parameter \(p\).
    \end{defi}
    Die Wahrscheinlichkeit der Ergebnisse einer Bernoulli-Kette können bei kleinen Längen mithilfe eines Baumdiagramms bestimmt werden.
    \begin{center}
\tikzstyle{level 1}=[level distance=2.5cm, sibling distance=8cm]
\tikzstyle{level 2}=[level distance=2.5cm, sibling distance=4cm]
\tikzstyle{level 3}=[level distance=2.5cm, sibling distance=3cm]
% definiert Knoten- und Endpunkte
% text width ändert die Boxbreite wobei 1em einem Zeichen entspricht
\tikzstyle{bag} = [circle, draw, text width=1em, inner sep=2pt, text centered]
\tikzstyle{end} = [circle, minimum width=5pt, fill, inner sep=0pt]
\scalebox{0.8}{\begin{tikzpicture}[grow=down, sibling distance=4cm, level distance=2.5cm]
  \tikzset{bag/.style={circle, draw=black, minimum size=6mm, inner sep=2pt}}

  \node[bag] {}
child {
  node (A) [bag] {$1$}
  child {
    node (AB) [bag] {$1$}
    child {
      node (ABB) [bag] {$1$}
      edge from parent node[left] {$p$}
    }
    child {
      node (ABnB) [bag] {$0$}
      edge from parent node[right] {$1-p$}
    }
    edge from parent node[left] {$p$}
  }
  child {
    node (AnB) [bag] {$0$}
    child {
      node (AnBB) [bag] {$1$}
      edge from parent node[left] {$p$}
    }
    child {
      node (AnBnB) [bag] {$0$}
      edge from parent node[right] {$1-p$}
    }
    edge from parent node[right] {$ 1-p$}
  }
  edge from parent node[left] {$p$}
}
  child {
  node (nA) [bag] {$0$}
  child {
    node (nAB) [bag] {$1$}
    child {
      node (nABB) [bag] {$1$}
      edge from parent node[left] {$p$}
    }
    child {
      node (nABnB) [bag] {$0$}
      edge from parent node[right] {$1-p$}
    }
    edge from parent node[left] {$p$}
  }
  child {
    node (nAnB) [bag] {$0$}
    child {
      node (nAnBB) [bag] {$1$}
      edge from parent node[left] {$p$}
    }
    child {
      node (nAnBnB) [bag] {$0$}
      edge from parent node[right] {$1-p$}
    }
    edge from parent node[right] {$1-p$}
  }
  edge from parent node[right] {$1-p$}
};

  % Pfad-Wahrscheinlichkeiten direkt unter den Knoten
  \node[below=2mm of ABB]   {$\vdots$};
  \node[below=2mm of AnBB]  {$\vdots$};
  \node[below=2mm of nABB]  {$\vdots$};
  \node[below=2mm of nAnBB] {$\vdots$};
  \node[below=2mm of nAnBnB] {$\vdots$};
  \node[below=2mm of nABnB] {$\vdots$};
  \node[below=2mm of AnBnB] {$\vdots$};
  \node[below=2mm of ABnB] {$\vdots$};

\end{tikzpicture}}
    \end{center}
    Die Abbildung zeigt das Baumdiagramm einer Bernoulli-Kette der Länge 3 mit \(1\) als Treffer und \(0\) als Niete sowie der Trefferwahrscheinlichkeit \(P(1) = p\). Da die einzelnen Bernoulli-Experimente unabhängig sind, wiederholen sich sich die Wahrscheinlichkeiten an den Ästen an jeder Stufe des Baumdiagramms.
\begin{bsp}{Beispiel Bernoulli-Kette der Länge 3}{}\index{Bernoulli-Kette}
 Für die Wahrscheinlichkeit des Ergebnisses \glqq Nur im 3. Versuch ein Treffer\grqq\ ergibt sich durch die Pfadregel\\ \(P(001) = (1-p)\cdot (1-p) \cdot p = \left(1-p\right)^2 \cdot p\). \\ Für das Ergebnis \glqq Mindestens zwei Treffer\grqq\ kann man daraus folgern\\ \(P((110); (011);(011);(111)) = 3 \cdot P(110) + P(111) = 3\cdot p^2 \cdot \left(1-p\right) + p^3\). 
\end{bsp}
\section{Die Binomialverteilung}\index{Zufallsgröße!Binomialverteilung}
Bei einer Bernoulli-Kette der Länge \(n\) besteht ein konkretes Ergebnis aus einer Folge von insgesamt \(n\) Nullen und Einsen. Oft ist aber nur die Anzahl der Treffer bei der Berechnung der Wahrscheinlichkeit von Interesse.  Gibt die Zufallsgröße \(X\) die Anzahl der Treffer einer Bernoulli-Kette der Länge \(n\) an, so kann \(X\) die Werte \(0;1;2;3; \ldots ; n\) annehmen. 

\scalebox{0.95}{
\tikzstyle{level 1}=[level distance=2.5cm, sibling distance=8cm]
\tikzstyle{level 2}=[level distance=2.5cm, sibling distance=4cm]
\tikzstyle{level 3}=[level distance=2.5cm, sibling distance=3cm]
% definiert Knoten- und Endpunkte
% text width ändert die Boxbreite wobei 1em einem Zeichen entspricht
\tikzstyle{bag} = [circle, draw, text width=1em, inner sep=2pt, text centered]
\tikzstyle{end} = [circle, minimum width=5pt, fill, inner sep=0pt]

\begin{tikzpicture}[grow=down, sibling distance=4cm, level distance=2.5cm]
  \tikzset{bag/.style={circle, draw=black, minimum size=6mm, inner sep=2pt}}

  \node[bag] {}
child {
  node (A) [bag] {$1$}
  child {
    node (AB) [bag] {$1$}
    child {
      node (ABB) [bag] {$1$}
      edge from parent node[left] {$0,95$}
    }
    child {
      node (ABnB) [bag] {$0$}
      edge from parent node[right] {$0,05$}
    }
    edge from parent node[left] {$0,95$}
  }
  child {
    node (AnB) [bag] {$0$}
    child {
      node (AnBB) [bag] {$0$}
      edge from parent node[left] {$0,95$}
    }
    child {
      node (AnBnB) [bag] {$0$}
      edge from parent node[right] {$0,05$}
    }
    edge from parent node[right] {$0,05$}
  }
  edge from parent node[left] {$0,95$}
}
  child {
  node (nA) [bag] {$0$}
  child {
    node (nAB) [bag] {$0$}
    child {
      node (nABB) [bag] {$0$}
      edge from parent node[left] {$0,95$}
    }
    child {
      node (nABnB) [bag] {$0$}
      edge from parent node[right] {$0,05$}
    }
    edge from parent node[left] {$0,95$}
  }
  child {
    node (nAnB) [bag] {$0$}
    child {
      node (nAnBB) [bag] {$0$}
      edge from parent node[left] {$0,95$}
    }
    child {
      node (nAnBnB) [bag] {$0$}
      edge from parent node[right] {$0,05$}
    }
    edge from parent node[right] {$0,05$}
  }
  edge from parent node[right] {$0,05$}
};
\end{tikzpicture}}
\newline
\begin{center}
 
\renewcommand{\arraystretch}{1.3}
\setlength{\tabcolsep}{16pt}
\begin{tabular}{|c|c|c|}
\hline
\rowcolor{green!15}
$\omega$ & $P(\omega)$ & $X=x$\\
\hline
111 & $0{,}95^{3}$                 & 3\\
\hline
110 & $0{,}95^{2}\cdot 0{,}05$     & 2\\
\hline
101 & $0{,}95^{2}\cdot 0{,}05$     & 2\\
\hline
100 & $0{,}95\cdot 0{,}05^{2}$     & 1\\
\hline
011 & $0{,}95^{2}\cdot 0{,}05$     & 2\\
\hline
010 & $0{,}95\cdot 0{,}05^{2}$     & 1\\
\hline
001 & $0{,}95\cdot 0{,}05^{2}$     & 1\\
\hline
000 & $0{,}05^{3}$                 & 0\\
\hline
\end{tabular}
   
\end{center}
 \begin{bsp}{}{}
Durch das obige Baumdiagramm ist folgendes Bernoulli-Experiment simuliert. \\ In einer Urne befinden sich \(19\) weiße und eine schwarze Kugel. Aus dieser Urne werden drei Kugeln \textbf{mit zurücklegen} gezogen und  \(1\) für eine weiße Kugel bzw. \(0\) für eine schwarze notiert. Das Zufallsexperiment kann damit durch eine Bernoulli-Kette der Länge \(3\) mit dem Parameter \(p=\dfrac{19}{20} = 0,95\) beschrieben werden. Die ZG \(X\) gibt die Anzahl der weißen Kugeln an. \\[0.2cm]
Aus der obigen Tabelle ist zu sehen, dass es 3  unterschiedliche Pfade für \(2\) Treffer, also \(X=2\),  gibt. Daraus ist leicht zu berechnen, dass \(P(X=2) = 3\cdot 0,95^2\cdot 0,05\) gilt.\\[0.2cm] Verallgemeinert kann man sehen, dass für die Anzahl der Pfade \(\binom{3}{k}\) gilt und sich die passende Wahrscheinlichkeit mit\\[0.2cm]  \(P(X=k) =\binom{3}{k} \cdot 0,95^k \cdot 0,05^{3-k} \)
\end{bsp}
\begin{satz}{Wahrscheinlichkeit in einer Bernoulli-Kette}{}\index{Zufallsgröße!Binomialverteilung!Wahrscheinlichkeit}
    Gegeben ist eine Bernoulli-Kette der Länge \(n\) mit \(n \in \mathds{N}\setminus\{0\}\) und der Trefferwahrscheinlichkeit \(p\). Die Zufallsgröße \(X\) gibt die Anzahl der Treffer an. \\[0.2cm]
    Dann beträgt die Wahrscheinlichkeit für genau \(k\) Treffer mit \(k\in\{0;1;2;3;\ldots ; n\}\) \\ \(P(X=k) = \binom{n}{k}\cdot p^k \cdot \left(1-p\right)^{n-k}\)
\end{satz}
\begin{defi}{Die Binomialverteilung}{}\index{Zufallsgröße!Binomialverteilung}
 Eine Zufallsgröße \(X\) heißt binomialverteilt nach \(P^n_p(X=k) = B(n,p)\) oder \(B(n,p)\)-verteilt, wenn gilt:
 \begin{itemize}
    \item \(n\) ist die Länge der Bernoulli-Kette
    \item \(p\) ist die Trefferwahrscheinlichkeit
     \item \(X\) kann die Werte \(0;1;2;3; \ldots ; n\) mit \(n\in \mathds{N}\setminus \{0\}\) annehmen,
     \item \(P(X=k) = \binom{n}{k}\cdot p^k \cdot \left(1-p\right)^{n-k}\) mit \(0\leq p\leq 1\).
 \end{itemize}
\end{defi}
\subsection{Die kumulative Binomialverteilung}
\index{Binomialverteilung!Kumulative}\index{Zufallsgröße!Binomialverteilung!Kumulative}
Durch die Anwendung zur Berechnung der Wahrscheinlichkeiten innerhalb der Bernoulli-Kette ist es möglich, auch ohne ein Baumdiagramm die Wahrscheinlichkeit einzelner Äste zu berechnen. In vielen Aufgaben muss man allerdings sehr viele einzelne Wahrscheinlichkeiten berechnen und addiere. In diesen Fällen kann man die kumulative Binomialverteilung \(F(n;p;k)\) einer ZG \(X\) nutzen.
\begin{satz}{Die kumulative Binomialverteilung}{}
Die kumulative Verteilung \(F(n;p;k)\) einer binomialverteilten ZG \(X\) ist damit\[F(n;p;k) = F^n_p(k) = P^n_p(X\leq k) = \sum\limits_{i=0}^k \binom{n}{i} \cdot p^{i}\cdot (1-p)^{n-i}\]
\end{satz}

\subsection{Anwendung der kumulativen Verteilung}

Häufig interessiert die Wahrscheinlichkeit, dass in einer Bernoulli-Kette mindestens ein Treffer auftritt. Das ist die Summe der Wahrscheinlichkeiten für einen Treffer, zwei Treffer, drei Treffer, \(\ldots\),  n Treffer. Diese Wahrscheinlichkeit lässt sich viel einfacher durch das \textit{Gegenereignis} \textbf{kein Treffer} berechnen.
\begin{satz}{Mindestens 1 Treffer}{}\index{Binomialverteilung!Mindestens ein Treffer}
    Die Wahrscheinlichkeit mindestens ein Treffer bei einer binomialverteilten ZG \(B(n,p)\) lässt sich mit der Gegenwahrscheinlichkeit kein Treffer sehr leicht berechnen. \[P_p^n(X\geq 1) = 1- P_p^n(X=0) = 1-q^n = 1- \left(1-p\right)^n\]
\end{satz}
Häufig tauchen in diesem Zusammenhang auch Fragestellungen auf, bei denen man entweder die Trefferwahrscheinlichkeit \(p\) oder die Kettenlänge \(n\) bestimmen muss. Da in der Fragestellung dreimal das Wort mindestens auftritt, nennt man solche Aufgaben 3-m-Aufgaben. 
\begin{bem}{3-m-Aufgaben}{}\index{Binomialverteilung!3-m-Aufgaben}
\setlength{\columnsep}{10mm}
\begin{multicols}{2}
\begin{enumerate}
    \item \textbf{Mindest-Trefferwahrscheinlichkeit $p$ bei gegebenem $n$}\\
    Wie groß muss die Wahrscheinlichkeit \(p\) \textbf{mindestens} sein, damit sich unter 5 Fahrradfahrern mit einer Wahrscheinlichkeit von \textbf{mindestens} \(90\%\) \textbf{mindestens} ein Helmträger befindet?
    \begin{equation*}
        \begin{split}
            P^5_p(X\geq 1) &\geq 0,9\\
            1-P^5_p(X=0)&\geq 0,9\\
            1-(1-p)^5 &\geq 0,9 \hspace{0.3cm}|\hspace{0.1cm} -1\\
            -(1-p)^5 &\geq -0,1 \hspace{0.3cm}|\hspace{0.1cm} \cdot(-1)\\
            (1-p)^5 &\leq 0,1 \hspace{0.3cm}|\hspace{0.1cm} \sqrt[5]{\hspace{0.5cm}}\\ 
            1-p &\leq \sqrt[5]{0,1} \hspace{0.3cm}|\hspace{0.1cm} -1 \\
            -p &\leq \sqrt[5]{0,1} -1 \hspace{0.3cm}|\hspace{0.1cm} \cdot (-1)\\
            p&\geq 1-\sqrt[5]{0,1} \approx 0,3690\\ &\approx 37\%
        \end{split}
    \end{equation*}
    Die Wahrscheinlichkeit für einen Helmträger muss damit mindestens \(37\%\) betragen.
    \item \textbf{Mindest-Anzahl an Versuchen $n$ bei gegebenem $p$}\\
    Die Wahrscheinlichkeit, dass ein Radfahrer einen Helm trägt, ist \(60\%\). Wie viele Radfahrer muss man \textbf{midenstens} betrachten, damit sich darunter mit einer Wahrscheinlichkeit von \textbf{mindestens} \(99,9\%\) \textbf{mindestens} ein Helmträger befindet. 
    \begin{equation*}
        \begin{split}
            P^n_{0,6}(X\geq 1) &\geq 0,999\\
            1-P^n_{0,6}(X=0)&\geq 0,999\\
            1-(0,4)^n &\geq 0,999 \hspace{0.3cm}|\hspace{0.1cm} -1\\
            -(0,4)^n &\geq -0,001 \hspace{0.3cm}|\hspace{0.1cm} \cdot (-1)\\
            (0,4)^n &\leq 0,001\hspace{0.3cm}|\hspace{0.1cm} \ln{(\hspace{0.3cm})}\\
            n\cdot \ln{(0,4)} &\leq \ln{(0,001)}\hspace{0.3cm}|\hspace{0.1cm} : \ln{(0,4)}\\
           n&\geq \frac{\ln{(0,001)}}{\ln{(0,4)}} \approx 7,5
        \end{split}
    \end{equation*}
    Es müssen mindestens 8 Radfahrer untersucht werden.
\end{enumerate}
\end{multicols}
\end{bem}
\subsection{Typische Formulierungen}
\begin{bem}{Typische Formulierungen}{}
    \begin{center}
    
\begin{tabular}{p{0.94\linewidth}}
\hline
\textbf{Typische Aufgabenformulierungen bei }$X\sim\mathrm{Bin}(n,p)$\\[6pt]

\textbf{Der Rechner liefert:}\qquad \(\mathrm{Binomial\;CD}(x;N,p)=P^n_p(X\le x)\)\\[6pt]

\textbf{So übersetzt du Texte in Casio-Eingaben:}\\[4pt]
\(\boxed{P^n_p(X\le x)}\) \quad „\textbf{höchstens} \(x\) Treffer“ \quad\(\Rightarrow\)\quad direkt \(\mathrm{CD}(x)\)\\[4pt]

\(\boxed{P^n_p(X< x)}\) \quad „\textbf{weniger als} \(x\) Treffer“ \quad\(\Rightarrow\)\quad \(\mathrm{CD}(x-1)\)\\[4pt]

\(\boxed{P^n_p(X\ge x)}\) \quad „\textbf{mindestens} \(x\) Treffer“ \quad\(\Rightarrow\)\quad \(1-\mathrm{CD}(x-1)\)\\[4pt]

\(\boxed{P^n_p(X> x)}\) \quad „\textbf{mehr als} \(x\) Treffer“ \quad\(\Rightarrow\)\quad \(1-\mathrm{CD}(x)\)\\[6pt]

\textbf{Entsprechend bei „nicht mehr als / nicht weniger als“:}\\[4pt]
„\textbf{nicht mehr als} \(x\)“ \(\Leftrightarrow P^n_p(X\le x)\) \(\Rightarrow\) \(\mathrm{CD}(x)\)\\[4pt]
„\textbf{nicht weniger als} \(x\)“ \(\Leftrightarrow P^n_p(X\ge x)\) \(\Rightarrow\) \(1-\mathrm{CD}(x-1)\)\\[6pt]

\textbf{Zwischen zwei Werten:}\\[4pt]
\(\boxed{P^n_p(a\le X\le b) = P^n_p(X\leq b) - P^n_p(X\leq a-1)} \) \quad\(\Rightarrow\)\quad \(\mathrm{CD}(b)-\mathrm{CD}(a-1)\)\\[4pt]
\(\boxed{P^n_p(a< X\le b)= P^n_p(X\leq b) - P^n_p(X\leq a)}\) \quad\(\Rightarrow\)\quad \(\mathrm{CD}(b)-\mathrm{CD}(a)\)\\
\hline
\end{tabular}
\end{center}

\end{bem}
\subsection{Taschenrechner Anleitungen}\index{Zufallsgröße!Binomialverteilung!Taschenrechner}
\begin{b8d}{Berechnung der kumulativen Binomialverteilung}{}
\begin{center}
\begin{tabular}{p{0.94\linewidth}}
\hline
\textbf{Route zur Binomial CD-Funktion}\\[4pt]
1) \taste{MODE/SETUP} \;\(\rightarrow\)\; Auswahlmenü\\
2) \taste{4} \;\(\rightarrow\)\; \textbf{DIST} (Verteilung)\\
3) Mit dem Cursor auf \textbf{Seite 2} wechseln \;\(\rightarrow\)\; \textbf{Binomial CD}\\
4) \taste{2} \;\(\rightarrow\)\; \textbf{Variablen eingeben}\\[4pt]
\textbf{Eingabereihenfolge:}\\
Zuerst \(\;x\) (Wert der Zufallsgröße) \(\rightarrow\) dann \(\;N\) (Kettenlänge) \(\rightarrow\) dann \(\;p\) (Trefferwahrscheinlichkeit).\\
\hline
\end{tabular}
\end{center}
\noindent
\textbf{Was rechnet Binomial CD hier?} In diesem Modus liefert der Rechner typischerweise
\[
\boxed{\text{Binomial CD}(x;N,p)=P^n_p(X\le x)}
\]
Also: „höchstens \(x\) Treffer“.
\end{b8d}
\begin{b8d}{Berechnung der Wahrscheinlichkeit in den Taschenrechner}{}
\begin{center}
\begin{tabular}{p{0.94\linewidth}}
\hline
\textbf{Route zur Funktion für exakt \(k\) Treffer (Binomial PD)}\\[4pt]
1) \taste{MODE/SETUP} \;\(\rightarrow\)\; Auswahlmenü\\
2) \taste{4} \;\(\rightarrow\)\; \textbf{DIST} (Verteilung)\\
3) \taste{4} \;\(\rightarrow\)\; \textbf{Binomial PD} (Probability Distribution)\\
4) \taste{2} \;\(\rightarrow\)\; \textbf{VAR} (Variablen eingeben)\\[6pt]
\textbf{Eingabereihenfolge:}\\
Zuerst \(\;x\) (Wert der Zufallsgröße) \(\rightarrow\) dann \(\;N\) (Kettenlänge) \(\rightarrow\) dann \(\;p\) (Trefferwahrscheinlichkeit).\\
\hline
\end{tabular}
\end{center}

\noindent
\textbf{Was rechnet Binomial PD?}
\[
\boxed{\text{Binomial PD}(x;N,p)=P^n_p(X=x)}
\]
Also: „genau \(x\) Treffer“.
\end{b8d}
\begin{b8d}{Berechnung der Binomialverteilung als Tabelle}{}
\begin{center}
\begin{tabular}{p{0.94\linewidth}}
\hline
\textbf{Route zur Binomialverteilung als Tabelle (LIST)}\\[4pt]
1) \taste{MODE/SETUP} \;\(\rightarrow\)\; Auswahlmenü\\
2) \taste{4} \;\(\rightarrow\)\; \textbf{DIST} (Verteilung)\\
3) \taste{4} \;\(\rightarrow\)\; \textbf{Binomial PD} \quad(\textit{Einzelwahrscheinlichkeiten})\\
4) \taste{1} \;\(\rightarrow\)\; \textbf{LIST} \quad(\textit{Tabelleneingabe})\\[6pt]

\textbf{Eingabereihenfolge:}\\
Zuerst die gewünschten \(x\)-Werte in der Liste (z.\,B. \(0,1,2,\dots\)) \(\rightarrow\)
dann \(\;N\) (Kettenlänge/Anzahl der Versuche) \(\rightarrow\)
dann \(\;p\) (Trefferwahrscheinlichkeit).\\[4pt]

\textbf{Ausgabe:}\\
In der Ergebnisspalte erscheint zu jedem eingetragenen \(x\) der Wert
\(\;P^n_p(X=x)\).\\
\hline
\end{tabular}
\end{center}

\noindent
\textbf{Was liefert die Tabelle hier?} In diesem Modus berechnet der Rechner
\[
\boxed{\mathrm{Binomial\;PD}(x;N,p)=P^n_p(X=x)}
\]
also: „genau \(x\) Treffer“ (für jedes \(x\) aus der Liste).
\end{b8d}
\begin{b8d}{Berechnung der kumulativen Binomialverteilung als Tabelle}{}
\begin{center}
\begin{tabular}{p{0.94\linewidth}}
\hline
\textbf{Route zur kumulativen Binomialverteilung als Tabelle (LIST)}\\[4pt]
1) \taste{MODE/SETUP} \;\(\rightarrow\)\; Auswahlmenü\\
2) \taste{4} \;\(\rightarrow\)\; \textbf{DIST} (Verteilung)\\
3) Mit dem Cursor auf \textbf{Seite 2} wechseln \;\(\rightarrow\)\; \textbf{Binomial CD}\\
4) \taste{1} \;\(\rightarrow\)\; \textbf{LIST} \quad(\textit{Tabelleneingabe})\\[6pt]

\textbf{Eingabereihenfolge:}\\
Zuerst die gewünschten \(x\)-Werte in der Liste (z.\,B. \(0,1,2,\dots\)) \(\rightarrow\)
dann \(\;N\) (Kettenlänge/Anzahl der Versuche) \(\rightarrow\)
dann \(\;p\) (Trefferwahrscheinlichkeit).\\[4pt]

\textbf{Ausgabe:}\\
In der Ergebnisspalte erscheint zu jedem eingetragenen \(x\) der Wert
\(\;P^n_p(X\le x)\).\\
\hline
\end{tabular}
\end{center}

\noindent
\textbf{Was liefert die Tabelle hier?} In diesem Modus berechnet der Rechner
\[
\boxed{\mathrm{Binomial\;CD}(x;N,p)=P^n_p(X\le x)}
\]
also: „höchstens \(x\) Treffer“ (für jedes \(x\) aus der Liste).
\end{b8d} 
\subsection{Erwartungswert und Varianz einer binomialverteilten Zufallsgröße}
    \begin{defi}{Erwartungswert und Varianz}{}\index{Binomialverteilung!Erwartungswert}\index{Zufallsgröße!Binomialverteilung!Erwartungswert}\index{Binomialverteilung!Varianz}\index{Zufallsgröße!Binomialverteilung!Varianz}\index{Zufallsgröße!Binomialverteilung!Standardabweichung}
\index{Binomialverteilung!Standardabweichung}
     Gegeben ist eine Bernoulli-Kette der Länge \(n\) mit der Trefferwahrscheinlichkeit \(p\). Für die Zufallsgröße \(X\) \glqq Anzahl der Treffer\grqq gilt:
     \begin{description}
         \item[Erwartungswert:] \(E(X) = \mu = n\cdot p\)
         \item[Varianz:] \(Var(X) = n\cdot p \cdot q = n\cdot p\cdot \left(1-p\right)\)
         \item[Standardabweichung:]\(\sigma = \sqrt{n\cdot p \cdot q } = \sqrt{n\cdot p\cdot \left(1-p\right)}\) 
     \end{description} 
    \end{defi}
    \begin{b8d}{}{}
Werden aus einer großen Gesamtheit nur wenige Elemente ausgewählt, darf man die interessierenden Wahrscheinlichkeiten näherungsweise mit der Bernoulli'schen Formel berechnen.
    \end{b8d}
    \begin{merke}{Werte der Binomialverteilung}{}
   Ist eine ZG \(X\) nach \(B(n,p)\) verteilt, so ist die Trefferanzahl \(k\) mit der größten Wahrscheinlichkeit entweder \begin{itemize}
       \item \(k=E(X)\) wenn \(\mu = E(X)\) ganzzahlig ist
       \item bei der von \(\mu = E(X)\) aus gesehenen nächstkleineren oder nächstgrößeren Trefferanzahl, wenn \(E(X)\) nicht ganzzahlig ist.
   \end{itemize}
    \end{merke}
    Im folgenden sollen einige Eigenschaften von Histogrammen betrachtet werden\footnote{Die hier gezeigten Histogramme sind aus \cite{klett_lambacher_schweizer_mathe12_bayern_2024} S.102}.
\begin{merke}{Eigenschaften spezieller Histogramme}{}
Die Histogramme einer nach \(B(n;p)\) verteilten Zufallsgröße \(X\) werden mit wachsenden \(n\) bei konstanten \(p\) flacher. Die Maximalwerte der Wahrscheinlichkeitsfunktionen nehmen dabei ab.
\begin{center}
    \includegraphics[width =1\textwidth]{Bilder/Histogramm0.png}
\end{center}
Die Histogramme einer nach \(B(n;p)\) verteilten Zufallsgröße \(X\) verschieben sich mit wachsenden \(p\) bei konstantem \(n\) nach rechts.
\begin{center}
     \includegraphics[width =1\textwidth]{Bilder/Histogramm1.png}
\end{center}
Wenn \(n\) konstant ist, dann nehmen die Maximalwerte der Wahrscheinlichkeitsfunktion bei \(p=0.5\) ihr Minimum an.
\end{merke}
\begin{b8d}{Symmetrie der Histogramme}{}
\begin{multicols}{2}

Das Histogramm einer nach \(B(n;p)\) verteilten Zufallsgröße \(X\) ist für \(p=0.5\) achsensymetrisch.
\begin{center}
     \includegraphics[width =0.45\textwidth]{Bilder/Histogramm2.png}
\end{center}
 \columnbreak
 Die Histogramme von nach \(B(n;p)\) und \(B(n;1-p)\) verteilten Zufallsgrößen \(X\) sind zueinander symmetrisch.
 \begin{center}
    \includegraphics[width =0.45\textwidth]{Bilder/Histogramm3.png}  
 \end{center}
\end{multicols}
\end{b8d}
\newpage
\subsection{\(\sigma\) - Umgebung}
\begin{defi}{\(\sigma\) - Umgebung}{}\index{Binomialverteilung!Sigma-Umgebung} \index{Zufallsgröße!Sigma-Umgebung}
Die \textbf{Die \( \sigma\)-Umgebung} beschreibt einen „typischen Bereich“ um den Erwartungswert \(\mu\).\\
Man nimmt den Erwartungswert und geht \textbf{eine Standardabweichung \(\sigma\)} nach links und nach rechts.

\[
U_{1}=[\,\mu-\sigma,\;\mu+\sigma\,]
\]

Allgemeiner: Die \textbf{\(k\sigma\)-Umgebung} ist der Bereich, der \textbf{\(k\) Standardabweichungen} nach links und rechts umfasst:
\[
U_{k}=[\,\mu-k\sigma,\;\mu+k\sigma\,]\quad (k>0).
\]

Für \(X\sim\mathrm{Bin}(n,p)\) gilt also:
\[
U_{k}=\Bigl[\,np-k\sqrt{np(1-p)},\;np+k\sqrt{np(1-p)}\,\Bigr].
\]    
\end{defi}
\begin{b8d}{Bedeutung der \(\sigma\) - Umgebung}{}
Werte \textbf{in der Sigma-Umgebung} sind „nicht überraschend“, weil sie in der normalen Streuung liegen.\\
Werte \textbf{weit außerhalb} (z.\,B. außerhalb von \(2\sigma\) oder \(3\sigma\)) sind eher \textbf{auffällig}.\\
\vspace{2mm}
\noindent\textbf{Skizze:}
\begin{center}
\begin{tikzpicture}[x=1cm,y=1cm,>=stealth]
  \def\a{0}   % Position mu
  \def\b{3}   % Abstand sigma

  % Achse
  \draw[->] (-4.2,0) -- (4.2,0) node[right] {$x$};

  % Markierungen
  \draw (\a,0.08) -- (\a,-0.08) node[below=3pt] {$\mu$};
  \draw (\a-\b,0.08) -- (\a-\b,-0.08) node[below=3pt] {$\mu-\sigma$};
  \draw (\a+\b,0.08) -- (\a+\b,-0.08) node[below=3pt] {$\mu+\sigma$};

  % 1-sigma-Umgebung hervorheben
  \draw[line width=1.2pt] (\a-\b,0) -- (\a+\b,0);

  % Klammer tiefer + Beschriftung tiefer
  \draw[decorate,decoration={brace,amplitude=5pt}]
    (\a+\b,-1.05) -- (\a-\b,-1.05)
    node[midway,below=8pt] {typischer Bereich (\(1\sigma\)-Umgebung)};

\end{tikzpicture}
\end{center}
\end{b8d}
\section{Hypothesentest}\index{Hypothesentest}
\begin{itemize}
\item Zwei sich ausschließende Hypothesen werden betrachtet
\begin{enumerate}
\item Nullhypothese $H_0$ 
\item Gegenhypothese $H_1$
\end{enumerate}
\item Anzahl der Treffer einer \textcolor{red}{Stichprobe} mit festgelegter Länge bildet die \textcolor{red}{Testgröße}
\item Wertebereich der Testgröße wird in den \textcolor{red}{kritischen Bereich} K (\textcolor{red}{Ablehnungsbereich}) und den \textcolor{red}{nichtkritischen Bereich} $\bar{K}$  (\textcolor{red}{Annahmebereich}) zerlegt
\item liegt der durch die Stichprobe gewonnene Wert der Testgröße in K, dann wird $H_0$ verworfen, ansonsten wird $H_0$ nicht verworfen (\textcolor{red}{Entscheidungsregel}). 
\item Fehler beim Testen von Hypothesen\\

\scalebox{1.2}{\begin{tabular}{|>{\columncolor{gray!15}}l|>{\columncolor{gray!10}}c|>{\columncolor{gray!10}}c|}
  \hline
  \rowcolor{gray!20}
  \textbf{Entscheidung} & \textbf{$H_0$ ist wahr.} & \textbf{$H_0$ ist falsch.} \\
  \hline
  $H_0$ wird abgelehnt. &
  \cellcolor{red!30}Fehler erster Art &
  \cellcolor{green!20}Richtige Entscheidung \\
  \hline
  $H_0$ wird nicht abgelehnt. &
  \cellcolor{green!20}Richtige Entscheidung &
  \cellcolor{cyan!20}Fehler zweiter Art \\
  \hline
\end{tabular}}
\begin{enumerate}
\item Fehler erster Art: $H_0$ wird verworfen, obwohl sie wahr ist. \index{Hypothesentest!Fehler 1. Art}
\item Fehler zweiter Art: $H_0$ wird beibehalten, obwohl sie falsch ist.\index{Hypothesentest!Fehler 2. Art}
\item Durch eine Veränderung der Entscheidungsregel kann man nur die Wahrscheinlichkeit
des Fehlers der einen Art auf Kosten der Wahrscheinlichkeit des Fehlers der anderen Art verringern.
\item Durch eine Erhöhung des Stichprobenumfangs können bei einem Test die Fehler
1. und 2. Art verringert werden. Allerdings ist eine solche Erhöhung in der Praxis auch mit erhöhten Kosten verbunden.
\end{enumerate}
\end{itemize}
\section{Stetige Zufallsgrößen}\index{Zufallsgröße!Stetige}
\begin{bsp}{Tropfen auf einem Tisch}{}

Auf einen Tisch wird versehentlich Wasser gekippt. Die meisten Tropfen landen in der Nähe der \textbf{Tischmitte}, weil dort die Quelle ist; zu den Rändern hin werden es weniger.

Wir betrachten nur eine Dimension:

\textbf{Zufallsgröße:} $X =$ \emph{Position eines zufällig ausgewählten Tropfens} (in cm) gemessen vom linken Rand.\\
Der Tisch sei $100$ cm lang, also:
\[
X \in [0,100].
\]

\textbf{Wichtig:} Hier sind \textbf{nicht} alle Intervalle gleich wahrscheinlich. Ein Tropfen ist eher bei $x\approx 50$ als bei $x\approx 5$.

\textbf{Idee:} Wir messen sehr viele Tropfenpositionen und zeichnen ein Histogramm. Je feiner wir die Klassen wählen, desto mehr nähert sich das Histogramm einer Kurve an.

Die folgenden Histogramme zeigen \textbf{relative Häufigkeiten} in Intervallen. Die Form ist „glockenförmig“: Mitte häufiger, Ränder seltener.

\begin{center}
\begin{tikzpicture}
\begin{axis}[
    width=0.92\textwidth,
    height=5.2cm,
    ymin=0, ymax=0.42,
    xmin=0, xmax=100,
    ybar,
    bar width=26pt,
    axis lines=left,
    xtick={0,20,40,60,80,100},
    ytick={0,0.1,0.2,0.3,0.4},
    xlabel={$x$ (cm)},
    ylabel={relative Häufigkeit},
    title={5 Klassen},
    nodes near coords,
    nodes near coords align={vertical},
    every node near coord/.append style={font=\scriptsize}
]
% Intervallmitten: 10,30,50,70,90
\addplot coordinates {(10,0.08) (30,0.24) (50,0.36) (70,0.24) (90,0.08)};
\end{axis}
\end{tikzpicture}
\end{center}

\textbf{Interpretation:} Z.\,B. liegen ca. $36\%$ der Tropfenpositionen im Bereich $[40,60)$ cm.
\begin{center}
\begin{tikzpicture}
\begin{axis}[
    width=0.92\textwidth,
    height=5.2cm,
    ymin=0, ymax=0.22,
    xmin=0, xmax=100,
    ybar,
    bar width=12pt,
    axis lines=left,
    xtick={0,10,20,30,40,50,60,70,80,90,100},
    ytick={0,0.05,0.10,0.15,0.20},
    xlabel={$x$ (cm)},
    ylabel={relative Häufigkeit},
    title={10 Klassen},
]
% Mitten: 5,15,...,95
\addplot coordinates {
(5,0.02) (15,0.06) (25,0.10) (35,0.14) (45,0.18)
(55,0.18) (65,0.14) (75,0.10) (85,0.06) (95,0.02)
};
\end{axis}
\end{tikzpicture}
\end{center}

\textbf{Merke:} Die Balken werden schmaler (kleineres $b$). Die Höhen ändern sich, weil die Anteile jetzt auf kleinere Intervalle verteilt werden.


\begin{center}
\begin{tikzpicture}
\begin{axis}[
    width=0.92\textwidth,
    height=5.2cm,
    ymin=0, ymax=0.11,
    xmin=0, xmax=100,
    ybar,
    bar width=5.6pt,
    axis lines=left,
    xtick={0,10,20,30,40,50,60,70,80,90,100},
    ytick={0,0.02,0.04,0.06,0.08,0.10},
    xlabel={$x$ (cm)},
    ylabel={relative Häufigkeit},
    title={20 Klassen},
]
% Mitten: 2.5,7.5,...,97.5
\addplot coordinates {
(2.5,0.005) (7.5,0.015) (12.5,0.025) (17.5,0.035) (22.5,0.045)
(27.5,0.055) (32.5,0.065) (37.5,0.075) (42.5,0.085) (47.5,0.095)
(52.5,0.095) (57.5,0.085) (62.5,0.075) (67.5,0.065) (72.5,0.055)
(77.5,0.045) (82.5,0.035) (87.5,0.025) (92.5,0.015) (97.5,0.005)
};
\end{axis}
\end{tikzpicture}
\end{center}
\end{bsp}
Bei stetigen Zufallsgrößen macht es keinen Sinn, einzelnen Punkten Wahrscheinlichkeiten als Balken zuzuordnen. Bei stetigen Zufallsgrößen rechnet man deshalb mit \textbf{Intervallen}.
\begin{defi}{Stetige Zufallsgrößen}{}
    Eine Zufallsgröße, die aus einem Intervall jede reelle Zahl als Wert annehmen kann, bezeichnet man als \textbf{\textcolor{red}{stetig}}. Ihr Wertemenge besteht somit aus einem Intervall.
\end{defi}
\begin{defi}{Dichtefunktion}{}\index{Zufallsgröße!Stetige!Dichtefunktion}

    Eine Funktion \(f\) heißt \textbf{Dichtefunktion} über \(\mathds{R}\), wenn gilt:
    \begin{enumerate}
        \item \(f(x)\geq 0\) für alle \(x\in \mathds{R}\) und
        \item \(\integral[limits-mode=limits,limits={-\infty, \infty}]{f(x)} =1\)
    \end{enumerate}
    Eine reelwertige Zufallsgröße \(X\) heißt \textbf{stetig} mit der Dichtefunktion \(f\), wenn für alle \(r,s \in I\) mit \(r\leq s\) gilt: \[P(r\leq X \leq s) =\integral[limits-mode=limits,limits={-\infty, \infty}]{f(x)}  \]

% --- Dichtefunktion (hier: "Glocke"). Du kannst die Formel ändern. ---
\pgfmathdeclarefunction{dens}{1}{%
  \pgfmathparse{0.78*exp(-((#1-0.8)^2)/(2*0.65^2))}%
}
\begin{tikzpicture}

% --- Bereich / Parameter ---
\pgfmathsetmacro{\xmin}{-1.2}
\pgfmathsetmacro{\xmax}{ 2.35}

% Automatische Position der Beschriftung links (y aus Kurve)
\pgfmathsetmacro{\xLabelAll}{0.55}
\pgfmathsetmacro{\yLabelAll}{0.55*dens(\xLabelAll)}

% Rechts: Intervall [r,s] und automatische Textpositionen
\pgfmathsetmacro{\r}{0.20}
\pgfmathsetmacro{\s}{1.30}
\pgfmathsetmacro{\xmid}{0.5*(\r+\s)}
\pgfmathsetmacro{\ymid}{dens(\xmid)}
\pgfmathsetmacro{\yProb}{0.78*\ymid}
\pgfmathsetmacro{\yInt}{0.45*\ymid}

\begin{groupplot}[ticklabel style={fill=none},   every tick label/.append style={fill=none},
  group style={group size=2 by 1, horizontal sep=1.1cm},
  width=0.55\linewidth,   % <-- streckt auf nahezu ganze Zeilenbreite
  height=0.4\linewidth,  % <-- passende Höhe (skalierbar)
  xmin=\xmin, xmax=\xmax,
  ymin=-0.02, ymax=0.9,
  axis lines=middle,
  axis line style={->},
  axis on top,
  xtick={-1,0,1,2},
  ytick={0.4,0.8},
  tick style={black},
  ticklabel style={font=\small},
  xlabel={$x$},
  ylabel={$y$},
  xlabel style={at={(axis description cs:1.02,0.05)},anchor=west},
  ylabel style={at={(axis description cs:0.05,1.02)},anchor=south},
  clip=false,
]

% -------- Links: Gesamtfläche ----------
\nextgroupplot
  \addplot[name path=curveA, very thick, blue, domain=-1.15:2.25, samples=220] {dens(x)};
  \addplot[name path=axisA,  draw=none, domain=-1.15:2.25] {0};

  \addplot[fill=green!20, fill opacity=0.55, draw=none]
    fill between[of=curveA and axisA];

  \node[green!40!black] at (axis cs:{\xLabelAll+0.25},{\yLabelAll - 0.1})
    {$\displaystyle \int_{-\infty}^{+\infty} f(x)\,dx = 1$};

  \node[blue, font=\large] at (axis cs:2.18,0.04) {$G_f$};

% -------- Rechts: Fläche r bis s ----------
\nextgroupplot
  \addplot[name path=curveB, very thick, blue, domain=-1.15:2.25, samples=220] {dens(x)};
  \addplot[name path=axisB,  draw=none, domain=-1.15:2.25] {0};

  \addplot[fill=green!20, fill opacity=0.55, draw=none]
    fill between[
      of=curveB and axisB,
      soft clip={domain=\r:\s}
    ];

  \addplot[green!60!black, thick] coordinates {(\r,0) (\r,{dens(\r)})};
  \addplot[green!60!black, thick] coordinates {(\s,0) (\s,{dens(\s)})};

  \node[font=\large] at (axis cs:\r,-0.035) {$r$};
  \node[font=\large] at (axis cs:\s,-0.035) {$s$};

  \node[green!40!black] at (axis cs:\xmid,{\yProb-0.15})
    {$\mathrm{P}(r\le X \le s)$};
  \node[green!40!black, font=\small] at (axis cs:\xmid,{\yInt-0.1})
    {$\displaystyle = \int_{r}^{s} f(x)\,dx$};

  \node[blue, font=\small] at (axis cs:2.18,0.03) {$G_f$};
\end{groupplot}

\end{tikzpicture}
\end{defi}
\begin{bsp}{Tropfen auf einem Tisch}{}
    Ein einfaches Modell für die \textbf{ Dichte}:
\[
f(x)=
\begin{cases}
\displaystyle \frac{30}{100}\left(\frac{x}{100}\right)^{2}\left(1-\frac{x}{100}\right)^{2}
& 0\le x\le 100,\\[0.8em]
0 & \text{sonst.}
\end{cases}
\]
Diese Dichte ist in der Mitte am größten und fällt zu den Rändern ab.
\begin{center}
\begin{tikzpicture}
\begin{axis}[
    width=0.92\textwidth,
    height=5.2cm,
    xmin=-2, xmax=102,
    ymin=0,  ymax=0.021,
    axis lines=left,
    scaled y ticks=false,
y tick label style={
  /pgf/number format/fixed,
  /pgf/number format/precision=3
},
    xtick={0,10,20,30,40,50,60,70,80,90,100},
    ytick={0,0.005,0.010,0.015,0.020},
    xlabel={$x$ (cm)},
    ylabel={Dichte $f(x)$},
    title={Dichtefunktion: Höhe „pro cm“},
]
% Glatte Dichte (Beta(3,3) skaliert auf [0,100]):
% f(x) = 0.3*(x/100)^2*(1-x/100)^2 für 0<=x<=100, sonst 0
\addplot[thick, blue, no marks, domain=0:100, samples=400]
  {0.3*(x/100)^2*(1 - x/100)^2};

% Außerhalb [0,100] ist die Dichte 0
\addplot[thick, blue, no marks, domain=-2:0, samples=2] {0};
\addplot[thick, blue, no marks, domain=100:102, samples=2] {0};

\end{axis}
\end{tikzpicture}
\end{center}
Die Dichte $f(x)$ ist keine Wahrscheinlichkeit, sondern eine \emph{Wahrscheinlichkeit pro Längeneinheit}.  
Wahrscheinlichkeiten bekommst du nur durch \textbf{Flächen} (Integrale).\\
Rechnen mit der Dichtefunktion
\[
f(x)=
\begin{cases}
\displaystyle 0.3\left(\frac{x}{100}\right)^2\left(1-\frac{x}{100}\right)^2 & 0\le x\le 100,\\[0.6em]
0 & \text{sonst.}
\end{cases}
\]
Nachweis: Gesamtfläche muss $1$ sein\\
Wir weisen nach:
\[
\int_{-\infty}^{\infty} f(x)\,dx=\int_{0}^{100} f(x)\,dx=1.
\]

Zuerst quadrieren und ausmultiplizieren:
\[
\left(1-\frac{x}{100}\right)^2
=1-\frac{2x}{100}+\frac{x^2}{10000}
=1-\frac{x}{50}+\frac{x^2}{10000}.
\]
Dann gilt für $0\le x\le 100$:
\[
f(x)=0.3\cdot\frac{x^2}{10000}\left(1-\frac{x}{50}+\frac{x^2}{10000}\right)
=0.3\left(\frac{x^2}{10000}-\frac{x^3}{500000}+\frac{x^4}{100000000}\right).
\]
Also:
\[
f(x)=3\cdot10^{-5}x^2-6\cdot10^{-7}x^3+3\cdot10^{-9}x^4.
\]

Nun integrieren wir auf $[0,100]$:
\[
\int_0^{100} f(x)\,dx
=
\int_0^{100}\left(3\cdot10^{-5}x^2-6\cdot10^{-7}x^3+3\cdot10^{-9}x^4\right)\,dx
\]
\[
=
\left[\,10^{-5}x^3-1.5\cdot10^{-7}x^4+6\cdot10^{-10}x^5\,\right]_{0}^{100}.
\]

Einsetzen von $x=100$ (und bei $x=0$ ergibt sich $0$):
\[
10^{-5}\cdot 100^3-1.5\cdot10^{-7}\cdot 100^4+6\cdot10^{-10}\cdot 100^5
=
10^{-5}\cdot 10^6-1.5\cdot10^{-7}\cdot 10^8+6\cdot10^{-10}\cdot 10^{10}
\]
\[
=10-15+6=1.
\]
Damit ist gezeigt:
\[
\boxed{\int_{0}^{100} f(x)\,dx=1.}
\]
Beispiel: Wahrscheinlichkeit $P(40\le X\le 60)$
\[
P(40\le X\le 60)=\int_{40}^{60} f(x)\,dx
=\int_{40}^{60}\left(3\cdot10^{-5}x^2-6\cdot10^{-7}x^3+3\cdot10^{-9}x^4\right)\,dx
\]
\[
=
\left[\,10^{-5}x^3-1.5\cdot10^{-7}x^4+6\cdot10^{-10}x^5\,\right]_{40}^{60}.
\]

Wir berechnen $F(60)$ und $F(40)$:

\medskip
\textbf{$F(60)$:}\quad
$60^3=216000,\;60^4=12960000,\;60^5=777600000$.
\[
F(60)=10^{-5}\cdot216000-1.5\cdot10^{-7}\cdot12960000+6\cdot10^{-10}\cdot777600000
\]
\[
=2.16-1.944+0.46656=0.68256.
\]

\textbf{$F(40)$:}\quad
$40^3=64000,\;40^4=2560000,\;40^5=102400000$.
\[
F(40)=10^{-5}\cdot64000-1.5\cdot10^{-7}\cdot2560000+6\cdot10^{-10}\cdot102400000
\]
\[
=0.64-0.384+0.06144=0.31744.
\]

Damit:
\[
P(40\le X\le 60)=F(60)-F(40)=0.68256-0.31744=0.36512.
\]
\[
\boxed{P(40\le X\le 60)\approx 0.36512\approx 36.5\%.}
\]
\end{bsp}
\begin{defi}{Erwartungswert, Varianz und Standardabweichung}{}\index{Zufallsgröße!Stetige!Erwartungswert}\index{Zufallsgröße!Stetige!Varianz}\index{Zufallsgröße!Stetige!Standardabweichung}
  Für die stetige Zufallsgröße \(X\) mit \(x\in \mathds{R}\) und der Dichtefunktion \(f(x)\) können folgende Kenngrößen definiert werden:
  \begin{description}
      \item[Erwartungswert:] \(E(X) = \mu = \integral[limits-mode=limits,limits={-\infty, \infty}]{x \cdot f(x)}\) 
      \item[Varianz:] \(Var(X) =  \integral[limits-mode=limits,limits={-\infty, \infty}]{\left(x-\mu \right)^2 \cdot f(x)}\) 
      \item[Standardabweichung:] \(\sigma = \sqrt{Var(X)}\) 
  \end{description}  
\end{defi}
    \section{Die Gauß'sche Glockenkurve}\index{Zufallsgröße!Stetige!Gauß'sche Glockenfunktion}
    \begin{defi}{Die Gauß'sche Glockenfunktion}{}
        Jede Funktion der Funktionenschar \[\varphi_{\mu, \sigma} : x\mapsto \dfrac{1}{\sigma \sqrt{2\pi}} \cdot e^{-\dfrac{\left(x-\mu\right)^2}{2\sigma^2}}\] mit \(\mu \in \mathds{R}\) und \(\sigma \in \mathds{R}^+\) bezeichnet man als eine Gauß'sche Glockenfunktion.\\
        Für die Werte \(\mu =0\) und \(\sigma =1\) ergibt sich die Funktion \[\varphi_{0,1}: x \mapsto \dfrac{1}{\sqrt{2\pi}} \cdot e^{-\dfrac{x^2}{2}}\]
    \end{defi}
    \begin{satz}{Eigenschaften der Scharfunktion \(\varphi_{\mu, \sigma}\)}{}\label{EigenschaftGauss}
        Jede Scharfunktion \(\varphi_{\mu, \sigma}\) besitzt folgende Eigenschaften:
        \begin{enumerate}
            \item \(\varphi_{\mu, \sigma} > 0\) für \( x\in \mathds{R}\)
            \item \(G_{\varphi_{\mu, \sigma}}\) ist achsensymmetrisch zur Geraden mit der Gleichung \(x= \mu\)
            \item \(\lim\limits_{x \longrightarrow \pm \infty}\varphi_{\mu, \sigma} =0\)
            \item \(G_{\varphi_{\mu, \sigma}}\) wächst im Intervall \(\left] -\infty; \mu \right]\) und fällt im Intervall \(\left[ \mu; \infty \right[\) 
            \item \(G_{\varphi_{\mu, \sigma}}\) hat als Extrempunkt nur den Hochpunkt \(H(\mu |\varphi_{\mu, \sigma}(\mu))\) mit \(\varphi_{\mu, \sigma}(\mu)) = \dfrac{1}{\sigma \sqrt{2\pi}}\)
            \item \(G_{\varphi_{\mu, \sigma}}\) hat die Wendepunkte \(W_{1,2} (\mu \pm \sigma|\varphi_{\mu, \sigma}(\mu \pm \sigma)))\) mit \( \varphi_{\mu, \sigma}(\mu \pm \sigma)) = \dfrac{1}{\sigma\sqrt{2\pi}}\cdot e^{-\frac{1}{2}}\)
            \item \(\integral[limits-mode=limits,limits={-\infty, \infty}]{\varphi_{\mu, \sigma}(x)} =1\)
            \item Die Integralfunktion \(\Phi_{\mu, \sigma}\) von \(\varphi_{\mu, \sigma}(x)\) mit \(\Phi_{\mu, \sigma} = \integral[limits-mode=limits,limits={-\infty, x}, variable={t}]{\varphi_{\mu, \sigma}(t)}\) kann \textcolor{red}{\textbf{nicht}} mithilfe elementarer Funktionen angegeben werden. Der Graph \(\Phi_{\mu, \sigma}\) ist punktsymmetrisch zu \(P(\mu|0,5)\) und streng monoton wachsend.
        \end{enumerate}    
        \end{satz}

\begin{bsp}{Dichtefunktion und Integralfunktion}{}

 \begin{tikzpicture}

% -------- Achse 1 (links): Dichten --------
\begin{axis}[
  width=14cm,
  height=8.5cm,
  xmin=-4, xmax=4,
  domain=-4:4,
  samples=700,
  grid=both,
  grid style={line width=.1pt, draw=gray!30},
  major grid style={line width=.2pt, draw=gray!50},
  axis lines=left,
  xlabel={$x$},
  ylabel={Dichte $\varphi(x)$ (linke Achse)},
  ymin=0,
  legend style={draw=none, fill=none, at={(0.02,0.98)}, anchor=north west},
  tick align=outside
]

% Dichten: drei Glocken
\addplot[thick, black] {1/(1*sqrt(2*pi))*exp(-0.5*((x-0)/1)^2)};
\addlegendentry{\textcolor{black}{Dichte $\mu=0,\ \sigma=1$}}

\addplot[thick, dashed, red] {1/(0.5*sqrt(2*pi))*exp(-0.5*((x-0)/0.5)^2)};
\addlegendentry{\textcolor{red}{Dichte $\mu=0,\ \sigma=0{,}5$}}

\addplot[thick, dotted, green] {1/(1.2*sqrt(2*pi))*exp(-0.5*((x-1)/1.2)^2)};
\addlegendentry{\textcolor{green}{Dichte $\mu=1,\ \sigma=1{,}2$}}

% Legendeneinträge für die CDF-Stile (damit alles in *einer* Legende steht)
\addlegendimage{very thick, dash dot}
\addlegendentry{\textcolor{black}{CDF $\mu=0,\ \sigma=1$}}

\addlegendimage{very thick, densely dashed}
\addlegendentry{\textcolor{red}{CDF $\mu=0,\ \sigma=0{,}5$}}

\addlegendimage{very thick, densely dotted}
\addlegendentry{\textcolor{green}{CDF $\mu=1,\ \sigma=1{,}2$}}

\end{axis}

% -------- Achse 2 (rechts): Verteilungsfunktionen --------
% (gleicher x-Bereich, zweite y-Achse rechts; dadurch "ein" Koordinatensystem mit zwei Skalen)
\begin{axis}[
  width=14cm,
  height=8.5cm,
  xmin=-4, xmax=4,
  domain=-4:4,
  samples=700,
  axis y line*=right,
  axis x line=none,
  ylabel={Verteilungsfunktion $\Phi(x)$ (rechte Achse)},
  ymin=0, ymax=1,
  tick align=outside,
  grid=none,
  legend style={draw=none},
]

% CDFs: drei Integralfunktionen (ohne erf), ohne Legende (Legendeneinträge kommen oben)
\addplot[very thick, dash dot, forget plot, black] {gausscdf(x,0,1)};
\addplot[very thick, densely dashed, forget plot, red] {gausscdf(x,0,0.5)};
\addplot[very thick, densely dotted, forget plot, green] {gausscdf(x,1,1.2)};

\end{axis}

\end{tikzpicture}
\end{bsp}

\begin{merke}{Besondere Werte der Gauß'schen Glockenkurve}{}
\begin{center}
\begin{tikzpicture}

% -----------------------------
% Parameter (frei anpassbar)
% -----------------------------
\pgfmathsetmacro{\MU}{2.2}
\pgfmathsetmacro{\SIG}{0.9}

% Hilfs-x-Werte
\pgfmathsetmacro{\A}{\MU-\SIG} % mu-sigma
\pgfmathsetmacro{\B}{\MU}      % mu
\pgfmathsetmacro{\C}{\MU+\SIG} % mu+sigma

% Skalenfaktor für PDF, damit sie optisch zum CDF-Plot passt
% (rein grafisch, nicht mathematisch nötig)
\pgfmathsetmacro{\PDFSCALE}{1.5}

\begin{axis}[
  width=10cm,
  height=8.5cm,
  axis lines=middle,
  xmin=0, xmax=5.5,
  ymin=0, ymax=1.25,
  xlabel={$x$},
  ylabel={$y$},
  xtick={0,\A,\B,\C},
  xticklabels={$0$,$\mu-\sigma$,$\mu$,$\mu+\sigma$},
  ytick={0,0.25,0.5,0.75,1.0,1.25},
  tick style={black},
  enlargelimits=false,
  clip=false,
  samples=220,
]

% -----------------------------
% Kurven: CDF (rot) und PDF (blau)
% -----------------------------
\addplot[name path=cdf, very thick, red, domain=0:5.5]
  ({x},{gausscdf(x,\MU,\SIG)});

\addplot[name path=pdf, very thick, blue, domain=0:5.5]
  ({x},{\PDFSCALE*gausspdf(x,\MU,\SIG)});

% -----------------------------
% Flächen W1, W2 unter der PDF
% -----------------------------
\path[name path=axisbase] (axis cs:0,0) -- (axis cs:5.5,0);

\addplot[blue!25] fill between[
  of=pdf and axisbase,
  soft clip={domain=\A:\B},
];

\addplot[blue!15] fill between[
  of=pdf and axisbase,
  soft clip={domain=\B:\C},
];

\node[blue] at (axis cs:{(\A+\B)/2 -0.7},0.4) {$W_1$};
\node[blue] at (axis cs:{(\B+\C)/2 +0.7},0.4) {$W_2$};

% -----------------------------
% Markierungen + Hilfslinien
% -----------------------------
% Werte an den drei Stellen:
\pgfmathsetmacro{\cdfA}{gausscdf(\A,\MU,\SIG)}
\pgfmathsetmacro{\cdfB}{gausscdf(\B,\MU,\SIG)}
\pgfmathsetmacro{\cdfC}{gausscdf(\C,\MU,\SIG)}
\pgfmathsetmacro{\pdfA}{\PDFSCALE*gausspdf(\A,\MU,\SIG)}
\pgfmathsetmacro{\pdfB}{\PDFSCALE*gausspdf(\B,\MU,\SIG)}
\pgfmathsetmacro{\pdfC}{\PDFSCALE*gausspdf(\C,\MU,\SIG)}

% gestrichelte Guides (wie im Bild)
\addplot[gray, dashed] coordinates {(0,\cdfC) (\C,\cdfC)};
\addplot[gray, dashed] coordinates {(\C,0) (\C,\cdfC)};
\addplot[gray, dashed] coordinates {(\B,0) (\B,\pdfB)};
\addplot[gray, dashed] coordinates {(\A,0) (\A,\pdfA)};

% Kreuz-Markierungen
\addplot[only marks, mark=x, mark size=3.5pt, very thick, red]
  coordinates {(\C,\cdfC)};
\addplot[only marks, mark=x, mark size=3.5pt, very thick, blue]
  coordinates {(\A,\pdfA) (\B,\pdfB) (\C,\pdfC)};

% -----------------------------
% Beschriftungen (nah am Original)
% -----------------------------
\node[red] at (axis cs:1.3,0.76) {$G_{\varphi_{\mu;\sigma}}$};
\node[blue] at (axis cs:4.6,0.10) {$\varphi_{\mu;\sigma}$};

\node[thick,red] at (axis cs:2.9,1.08)
  {$P(\mu+\sigma)=\Phi_{\mu;\sigma}(\mu+\sigma)$};

\node[green!60!black] at (axis cs:3.65,0.63)
  {$\Phi_{\mu;\sigma}(\mu+\sigma)$};

% -----------------------------
% Grüne Integral-Skizze (Fläche bis x = mu+sigma)
% -----------------------------


\addplot[green!30,] fill between[
  of=pdf and axisbase,
  soft clip={domain=0:\C},
];

\node[green!60!black] at (axis cs:4.15,0.50)
  {$\int_{-\infty}^{\mu+\sigma}\varphi_{\mu;\sigma}(x)\,dx$};

% kleine H-Markierung (optional)
\node[cyan!60!black] at (axis cs:2.45,0.48) {\large H};

\end{axis}
\end{tikzpicture}
    
\end{center}
\end{merke}
\begin{bsp}{Bestimmung von \(\mu\) und \(\sigma\) am Graphen}{}
\begin{center}

\begin{tikzpicture}
% Parameter wie im Bild
\pgfmathsetmacro{\MU}{1}
\pgfmathsetmacro{\SIG}{1.5}

\pgfmathsetmacro{\A}{\MU-\SIG} % mu-sigma
\pgfmathsetmacro{\B}{\MU}      % mu
\pgfmathsetmacro{\C}{\MU+\SIG} % mu+sigma

% Funktionswerte (für Markerpositionen)
\pgfmathsetmacro{\yA}{gausspdf(\A,\MU,\SIG)}
\pgfmathsetmacro{\yB}{gausspdf(\B,\MU,\SIG)}
\pgfmathsetmacro{\yC}{gausspdf(\C,\MU,\SIG)}

\begin{axis}[
  width=15cm,
  height=8cm,
  axis lines=middle,
  xmin=-3.0, xmax=5.0,
  ymin=0, ymax=0.32,
  xlabel={$x$},
  ylabel={$y$},
  xtick={-2,-1,0,1,2,3,4},
  ytick={0.1,0.2,0.3},
  yticklabels={0{,}1,0{,}2,0{,}3}, % deutsches Komma wie im Bild
  grid=both,
  major grid style={gray!60, line width=0.35pt},
  minor grid style={gray!35, line width=0.25pt},
  minor tick num=1,
  tick style={black},
  enlargelimits=false,
  clip=false,
]

% Glockenkurve (PDF)
\addplot[very thick, cyan!70!blue, samples=260, domain=-3:5]
  ({x},{gausspdf(x,\MU,\SIG)});

% Linke Beschriftung G_{phi_{mu;sigma}} (wie im Bild, auch wenn's eigentlich pdf ist)
\node[cyan!70!blue] at (axis cs:-2.7,0.055) {$G_{\varphi_{\mu;\sigma}}$};

% Gestrichelte Vertikalen bei mu-sigma, mu, mu+sigma bis zum jeweiligen Punkt
\addplot[gray, dashed] coordinates {(\A,0) (\A,\yA)};
\addplot[gray, dashed] coordinates {(\B,0) (\B,\yB)};
\addplot[gray, dashed] coordinates {(\C,0) (\C,\yC)};

% Marker (Kreuz) bei den drei Punkten
\addplot[only marks, mark=x, mark size=4.5pt, very thick, cyan!70!blue]
  coordinates {(\A,\yA) (\B,\yB) (\C,\yC)};

% Labels W1, H, W2
\node[cyan!70!blue] at (axis cs:{\A-0.35},{\yA+0.02}) {$W_1$};
\node[cyan!70!blue] at (axis cs:{\B+0.05},{\yB+0.035}) {$\mathrm{H}$};
\node[cyan!70!blue] at (axis cs:{\C+0.25},{\yC+0.02}) {$W_2$};

% Rote Markierungen auf der x-Achse (kleine Striche)
\addplot[red, very thick] coordinates {(\A,0) (\A,0.01)};
\addplot[red, very thick] coordinates {(\B,0) (\B,0.01)};
\addplot[red, very thick] coordinates {(\C,0) (\C,0.01)};

% Rote Texte unten
\node[red] at (axis cs:\A,-0.04) {$\mu-\sigma\approx -0{,}5$};
\node[red] at (axis cs:\B,-0.038) {$\mu=1$};
\node[red] at (axis cs:\C,-0.04) {$\mu+\sigma\approx 2{,}5$};

% Maßpfeile für sigma links/rechts (rote Doppelpfeile)
% In axis coordinates: wir zeichnen die Pfeile unterhalb der Achse
\draw[red, very thick, <->]
  (axis cs:\A,-0.07) -- (axis cs:\B,-0.07)
  node[midway, below=2pt] {$\sigma\approx 1{,}5$};

\draw[red, very thick, <->]
  (axis cs:\B,-0.07) -- (axis cs:\C,-0.07)
  node[midway, below=2pt] {$\sigma\approx 1{,}5$};

\end{axis}
\end{tikzpicture}   
\end{center}
   \begin{itemize}
       \item Ablesen von \(\mu\) aus dem Graphen \(\longleftrightarrow \mu = 1\)
       \item Mit Satz \ref{EigenschaftGauss} und der Eigenschaft \(H(\mu| \varphi_{\mu, \sigma} (\mu))\) kann \(\mu\) abgelesen werden und \(\sigma \) berechnet werden
       \item Es gilt \(\varphi_{\mu, \sigma} (\mu) = \dfrac{1}{\sigma\sqrt{2\pi}} \longleftrightarrow 0,26 \approx \dfrac{1}{\sigma\sqrt{2\pi}}\)
       \item \(\sigma \approx \dfrac{1}{0,26\cdot \sqrt{2\pi}} \approx 1,5\)
   \end{itemize}

\end{bsp}